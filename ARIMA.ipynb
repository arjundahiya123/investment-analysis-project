{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12623c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the following libraries: \n",
    "\n",
    "    # pandas (for data manipulation)\n",
    "    # import pandas as pd\n",
    "    \n",
    "    # numpy (for numerical operations)\n",
    "    # import numpy as np\n",
    "    \n",
    "    # matplotlib (for data visualization)\n",
    "    #import matplotlib as plt \n",
    "    \n",
    "    # statsmodels (to use ARIMA)\n",
    "    # from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c7e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import the dataset \n",
    "    \n",
    "    # Load the time series data into a pandas DataFrame\n",
    "    # This can be done using functions available with pandas \n",
    "    \n",
    "    # For example, if the data is in a csv file:\n",
    "    # data = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24505498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Modify the dataset\n",
    "\n",
    "    # Keep relevant columns, such as opening and closing prices, and the date\n",
    "    # Calculate financial ratios, such as moving averages, if they are not already in the dataset\n",
    "    # Fill in missing values if needed (probably not) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Separate the data into training and testing datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8e7a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualize the data and conduct the ADF test\n",
    "\n",
    "    # Use matplotlib to visualize the data\n",
    "    # Conduct the ADF test, which determines if the data is stationary or not\n",
    "    # If the data is not stationary, differencing is needed to convert it into stationary data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Optimize the parameters (p, d, q) and create the ARIMA model\n",
    "\n",
    "    # Determine (p,d,q) based on the data's characteristics\n",
    "    # ACF plot is used to determine p (autoregressive AR)\n",
    "    # PACF plot is used to determine q (moving average MA)\n",
    "    \n",
    "    # Create the ARIMA model object and fit it to the data\n",
    "    \n",
    "    # Examples of useful python code:\n",
    "    # p, d, q = 1, 1, 1\n",
    "    # model = ARIMA(data, order(p,d,q))\n",
    "    # model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Train the ARIMA model\n",
    "\n",
    "    # Train the model using model_fit = model.fit()\n",
    "    # Forecast the time series usin model_fit.forecast()\n",
    "    # model_fit.forecast(steps=6)   #'steps' parameter for # of future steps to forecast\n",
    "    # Analyze the model's performance by comparing the predicted values with actual values from the testing dataset\n",
    "    # print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Observe what the predictions look like\n",
    "    # Predicted values:\n",
    "    # y_pred = pd.Series(model.forecast(test_set_size)[0], index=df.value[sample_size].index)\n",
    "    # Actual values:\n",
    "    # y_true = df.value[sample_size]\n",
    "\n",
    "    # Print predictions\n",
    "    # print(np.array(y_pred).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f8190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Measure error of predictions using error metrics/functions popular for general regression models\n",
    "    # Mean absolute error\n",
    "    # mae = np.mean(np.abs(y_pred - y_true))\n",
    "    \n",
    "    # Mean absolute percentage error\n",
    "    # mape = np.mean(np.abs(y_pred - y_true)/np.abs(y_true))\n",
    "    \n",
    "    # Mean percentage error\n",
    "    # mpe = np.mean((y_pred - y_true)/y_true)\n",
    "    \n",
    "    # Root mean squared\n",
    "    # rmse = np.mean((y_pred - y_true)**2)**.5\n",
    "    \n",
    "    # Correlation Coefficient\n",
    "    # corr = np.corrcf(y_pred, y_true)[0, 1]\n",
    "    \n",
    "    \n",
    "    # Mean absolute scaled error (better for time-series data)\n",
    "    # n = np.array(df[sample_size]).shape[0]\n",
    "    # d = np.abs(np.diff(np.array(df[sample_size].value))).sum()/(n-1)\n",
    "    \n",
    "    # errors = np.abs(y_true - y_pred)\n",
    "    # print(errors.mean()/d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
